<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link href=https://ruihan.org/courses/cs224n/lec-notes/ rel=canonical><meta name=lang:clipboard.copy content="Copy to clipboard"><meta name=lang:clipboard.copied content="Copied to clipboard"><meta name=lang:search.language content=en><meta name=lang:search.pipeline.stopwords content=True><meta name=lang:search.pipeline.trimmer content=True><meta name=lang:search.result.none content="No matching documents"><meta name=lang:search.result.one content="1 matching document"><meta name=lang:search.result.other content="# matching documents"><meta name=lang:search.tokenizer content=[\s\-]+><link rel="shortcut icon" href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.1, mkdocs-material-4.6.3"><title>CS224N Lecture Notes - RUIHAN.ORG</title><link rel=stylesheet href=../../../assets/stylesheets/application.adb8469c.css><link rel=stylesheet href=../../../assets/stylesheets/application-palette.a8b3c06d.css><meta name=theme-color content><script src=../../../assets/javascripts/modernizr.86422ebf.js></script><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link rel=stylesheet href=../../../assets/fonts/material-icons.css></head> <body dir=ltr data-md-color-primary=black data-md-color-accent=black> <svg class=md-svg> <defs> <svg xmlns=http://www.w3.org/2000/svg width=416 height=448 viewbox="0 0 416 448" id=__github><path fill=currentColor d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay data-md-component=overlay for=__drawer></label> <a href=#cs224n-natural-language-processing-with-deep-learning tabindex=0 class=md-skip> Skip to content </a> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid"> <div class=md-flex> <div class="md-flex__cell md-flex__cell--shrink"> <a href=https://ruihan.org title=RUIHAN.ORG aria-label=RUIHAN.ORG class="md-header-nav__button md-logo"> <i class=md-icon></i> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title> <span class=md-header-nav__topic> RUIHAN.ORG </span> <span class=md-header-nav__topic> CS224N Lecture Notes </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search></label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input aria-label=search name=query placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=query data-md-state=active> <label class="md-icon md-search__icon" for=__search></label> <button type=reset class="md-icon md-search__icon" data-md-component=reset tabindex=-1> &#xE5CD; </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=result> <div class=md-search-result__meta> Type to start searching </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <div class=md-header-nav__source> <a href=https://github.com/iurnah/ruihan.org title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> iurnah/ruihan.org </div> </a> </div> </div> </div> </nav> </header> <div class=md-container> <nav class="md-tabs md-tabs--active" data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../books/accelerated-cpp/notes/ class=md-tabs__link> Books </a> </li> <li class=md-tabs__item> <a href=./ class="md-tabs__link md-tabs__link--active"> Course Notes </a> </li> <li class=md-tabs__item> <a href=../../../leetcode/array/notes/ class=md-tabs__link> Leetcode </a> </li> <li class=md-tabs__item> <a href=../../../research/coalition-game/notes/ class=md-tabs__link> Research </a> </li> <li class=md-tabs__item> <a href=../../../seedlabs/public-key-cryptography-and-pki/notes/ class=md-tabs__link> SEED Labs </a> </li> </ul> </div> </nav> <main class=md-main role=main> <div class="md-main__inner md-grid" data-md-component=container> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" data-md-level=0> <label class="md-nav__title md-nav__title--site" for=__drawer> <a href=https://ruihan.org title=RUIHAN.ORG class="md-nav__button md-logo"> <i class=md-icon></i> </a> RUIHAN.ORG </label> <div class=md-nav__source> <a href=https://github.com/iurnah/ruihan.org title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> iurnah/ruihan.org </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-1 type=checkbox id=nav-1> <label class=md-nav__link for=nav-1> Books </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-1> Books </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../books/accelerated-cpp/notes/ title="Accelerated C++" class=md-nav__link> Accelerated C++ </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-2 type=checkbox id=nav-2 checked> <label class=md-nav__link for=nav-2> Course Notes </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-2> Course Notes </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-toggle md-nav__toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> CS224N Lecture Notes </label> <a href=./ title="CS224N Lecture Notes" class="md-nav__link md-nav__link--active"> CS224N Lecture Notes </a> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc>Table of contents</label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#lecture-1-introduction-to-nlp-and-deep-learning class=md-nav__link> Lecture 1 Introduction to NLP and Deep Learning </a> </li> <li class=md-nav__item> <a href=#lecture-2-word-vector-representations-word2vec class=md-nav__link> Lecture 2 Word Vector Representations: word2vec </a> </li> <li class=md-nav__item> <a href=#lecture-3-advanced-word-vector-representations class=md-nav__link> Lecture 3 Advanced Word Vector Representations </a> </li> <li class=md-nav__item> <a href=#assignment-1-spring-2019 class=md-nav__link> Assignment 1 (Spring 2019) </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#review-materials class=md-nav__link> Review materials </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#lecture-4-word-window-classification-and-neural-networks class=md-nav__link> Lecture 4 Word Window Classification and Neural Networks </a> </li> <li class=md-nav__item> <a href=#lecture-5-backpropagation-feb-24-2019 class=md-nav__link> Lecture 5 Backpropagation (Feb 24, 2019) </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#details-of-backpropagation class=md-nav__link> Details of backpropagation </a> </li> <li class=md-nav__item> <a href=#iterpretations-of-backpropagation-using-simple-function class=md-nav__link> Iterpretations of backpropagation using simple function. </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#lecture-6-dependency-parsing-feb-27-2019 class=md-nav__link> Lecture 6 Dependency Parsing (Feb 27, 2019) </a> </li> <li class=md-nav__item> <a href=#lecture-8 class=md-nav__link> Lecture 8 </a> </li> <li class=md-nav__item> <a href=#lecture-9-machine-translation-and-advanced-recurrent-lstms-and-grus class=md-nav__link> Lecture 9 Machine Translation and Advanced Recurrent LSTMs and GRUs </a> </li> <li class=md-nav__item> <a href=#reference class=md-nav__link> Reference </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../write-up/ title="CS224N Write-up" class=md-nav__link> CS224N Write-up </a> </li> <li class=md-nav__item> <a href=../../6.431-probability/notes/ title="6.431 Probability" class=md-nav__link> 6.431 Probability </a> </li> <li class=md-nav__item> <a href=../../func-prog-in-scala/notes/ title="Func Prog Principles in Scala" class=md-nav__link> Func Prog Principles in Scala </a> </li> <li class=md-nav__item> <a href=../../9chap-dynamic-prog/notes/ title="Nine Chapter Dynamic Prog" class=md-nav__link> Nine Chapter Dynamic Prog </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Leetcode </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-3> Leetcode </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../leetcode/array/notes/ title=Array class=md-nav__link> Array </a> </li> <li class=md-nav__item> <a href=../../../leetcode/binary-search/notes/ title="Binary Search" class=md-nav__link> Binary Search </a> </li> <li class=md-nav__item> <a href=../../../leetcode/backtracking/notes/ title=Backtracking class=md-nav__link> Backtracking </a> </li> <li class=md-nav__item> <a href=../../../leetcode/dynamic-programming/notes/ title="Dynamic Programming" class=md-nav__link> Dynamic Programming </a> </li> <li class=md-nav__item> <a href=../../../leetcode/union-find/notes/ title="Union Find" class=md-nav__link> Union Find </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> Research </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-4> Research </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../research/coalition-game/notes/ title="Coalition Game" class=md-nav__link> Coalition Game </a> </li> <li class=md-nav__item> <a href=../../../research/contextual-bandit/notes/ title="Contextual Multi-Armed Bandit" class=md-nav__link> Contextual Multi-Armed Bandit </a> </li> <li class=md-nav__item> <a href=../../../research/tfidf-score/notes/ title="TF-IDF for Information Retrieval" class=md-nav__link> TF-IDF for Information Retrieval </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> SEED Labs </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-5> SEED Labs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../seedlabs/public-key-cryptography-and-pki/notes/ title="Public Key Cryptography and PKI" class=md-nav__link> Public Key Cryptography and PKI </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc>Table of contents</label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#lecture-1-introduction-to-nlp-and-deep-learning class=md-nav__link> Lecture 1 Introduction to NLP and Deep Learning </a> </li> <li class=md-nav__item> <a href=#lecture-2-word-vector-representations-word2vec class=md-nav__link> Lecture 2 Word Vector Representations: word2vec </a> </li> <li class=md-nav__item> <a href=#lecture-3-advanced-word-vector-representations class=md-nav__link> Lecture 3 Advanced Word Vector Representations </a> </li> <li class=md-nav__item> <a href=#assignment-1-spring-2019 class=md-nav__link> Assignment 1 (Spring 2019) </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#review-materials class=md-nav__link> Review materials </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#lecture-4-word-window-classification-and-neural-networks class=md-nav__link> Lecture 4 Word Window Classification and Neural Networks </a> </li> <li class=md-nav__item> <a href=#lecture-5-backpropagation-feb-24-2019 class=md-nav__link> Lecture 5 Backpropagation (Feb 24, 2019) </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#details-of-backpropagation class=md-nav__link> Details of backpropagation </a> </li> <li class=md-nav__item> <a href=#iterpretations-of-backpropagation-using-simple-function class=md-nav__link> Iterpretations of backpropagation using simple function. </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#lecture-6-dependency-parsing-feb-27-2019 class=md-nav__link> Lecture 6 Dependency Parsing (Feb 27, 2019) </a> </li> <li class=md-nav__item> <a href=#lecture-8 class=md-nav__link> Lecture 8 </a> </li> <li class=md-nav__item> <a href=#lecture-9-machine-translation-and-advanced-recurrent-lstms-and-grus class=md-nav__link> Lecture 9 Machine Translation and Advanced Recurrent LSTMs and GRUs </a> </li> <li class=md-nav__item> <a href=#reference class=md-nav__link> Reference </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1 id=cs224n-natural-language-processing-with-deep-learning>CS224N: Natural Language Processing with Deep Learning<a class=headerlink href=#cs224n-natural-language-processing-with-deep-learning title="Permanent link">&para;</a></h1> <h2 id=lecture-1-introduction-to-nlp-and-deep-learning>Lecture 1 Introduction to NLP and Deep Learning<a class=headerlink href=#lecture-1-introduction-to-nlp-and-deep-learning title="Permanent link">&para;</a></h2> <ul> <li>Representations of NLP levels: Semantics</li> <li>Traditional V.S. DL (rules v.s. sophisticated algorithm)</li> <li>Applications:<ul> <li>Sentiment Analysis</li> <li>Question Answering system</li> <li>Dialogue agents / response generation</li> </ul> </li> </ul> <h2 id=lecture-2-word-vector-representations-word2vec>Lecture 2 Word Vector Representations: word2vec<a class=headerlink href=#lecture-2-word-vector-representations-word2vec title="Permanent link">&para;</a></h2> <ul> <li>"one-hot" representation, localist representation</li> <li>distributional similarity based representations<ul> <li>"You shall know a word by the company it keeps” (J. R. Firth 1957:11)"</li> <li>dense vector for each word type, chosen so that it is good at predicting other words appearing in its context (gets a bit recursive)</li> </ul> </li> <li>Learning neural network word embeddings<ul> <li>model <span><span class=MathJax_Preview>p(\text{context} | w_t) = ?</span><script type=math/tex>p(\text{context} | w_t) = ?</script></span></li> <li>loss function: <span><span class=MathJax_Preview>J = 1 - p(w_{-t}|w_{t})</span><script type=math/tex>J = 1 - p(w_{-t}|w_{t})</script></span>, <span><span class=MathJax_Preview>w_{-t}</span><script type=math/tex>w_{-t}</script></span>, context words that doesn't include word <span><span class=MathJax_Preview>w_t</span><script type=math/tex>w_t</script></span>.</li> </ul> </li> <li>word2vec<ul> <li>Skip-grams (SG) - predict context words given target center words</li> <li>Continuous Bag of Words (CBOW) - predict target center word from bag-of-words context words</li> </ul> </li> <li>2 training methods<ul> <li>hierarchical softmax</li> <li>negative sampling: tain binary logistic regression for a true pair versus a couple of noice pairs.</li> </ul> </li> <li>Core ideas of SG prediction<ul> <li>maximize the prediction of the model <span><span class=MathJax_Preview>p(\text{context} | w_t) = ?</span><script type=math/tex>p(\text{context} | w_t) = ?</script></span> for all context words in the form of the cost function <span><span class=MathJax_Preview>J(\theta)</span><script type=math/tex>J(\theta)</script></span>.</li> <li>cost function: $$ J'(\theta) = \prod_{t=1}^T\prod_{\substack{-m \le j \le m\ j \ne 0}} p(w_{t+j}|w_t; \theta) $$</li> <li>Negative log likelihood $$ J(\theta) = -\frac{1}{T} \sum_{t=1}^T\sum_{\substack{-m \le j \le m\ j \ne 0}} \log p(w_{t+j}|w_t) $$</li> <li>softmax $$ p(o|c) = \frac{\exp(u_o^T v_c)}{\sum_{w=1}^{v}\exp(u_w^T v_c)} $$</li> </ul> </li> <li>What's really mean when you say train word2vec model<ul> <li>optimize the parameter <span><span class=MathJax_Preview>\theta</span><script type=math/tex>\theta</script></span>, which is a <span><span class=MathJax_Preview>R^{2\cdot d \cdot V}</span><script type=math/tex>R^{2\cdot d \cdot V}</script></span>, <span><span class=MathJax_Preview>d</span><script type=math/tex>d</script></span> is the word vector dimention, <span><span class=MathJax_Preview>V</span><script type=math/tex>V</script></span> is the vacabular size, each word is represented by 2 vectors!</li> <li>Compute all vector gradients!!!</li> </ul> </li> <li>Gradient calculation (lecture slides)</li> </ul> <h2 id=lecture-3-advanced-word-vector-representations>Lecture 3 Advanced Word Vector Representations<a class=headerlink href=#lecture-3-advanced-word-vector-representations title="Permanent link">&para;</a></h2> <ul> <li>Compare count based and direct prediction</li> <li>count based: LSA, HAL (Lund &amp; Burgess), COALS (Rohde et al), Hellinger-PCA (Lebret &amp; Collobert)<ul> <li><strong>Fast training</strong></li> <li><strong>Efficient usage of statistics</strong></li> <li>Primarily used to capture word similarity</li> <li>Disproportionate importance given to large counts</li> </ul> </li> <li>direct prediction: NNLM, HLBL, RNN, Skip-gram/CBOW, (Bengio et al; Collobert &amp; Weston; Huang et al; Mnih &amp; Hinton; Mikolov et al;Mnih &amp; Kavukcuoglu)<ul> <li>Scales with corpus size</li> <li>Inefficient usage of statistics</li> <li><strong>Can capture complex patterns beyond word similarity</strong></li> <li><strong>Generate improved performance on other tasks</strong></li> </ul> </li> <li>Combining the best of both worlds: GloVe<ul> <li>Fast training</li> <li>Scalable to huge corpora</li> <li>Good performance even with small corpus, and small vectors</li> </ul> </li> <li>How to evaluate word2vec?<ul> <li>Intrinsic:<ul> <li>Evaluation on a specific/intermediate subtask</li> <li>Fast to compute</li> <li>Helps to understand that system</li> <li>Not clear if really helpful unless correlation to real task is established</li> </ul> </li> <li>Extrinsic:<ul> <li>Evaluation on a real task</li> <li>Can take a long time to compute accuracy</li> <li>Unclear if the subsystem is the problem or its interaction or other subsystems</li> <li>If replacing exactly one subsystem with another improves accuracy --&gt; Winning!</li> </ul> </li> </ul> </li> </ul> <h2 id=assignment-1-spring-2019>Assignment 1 (Spring 2019)<a class=headerlink href=#assignment-1-spring-2019 title="Permanent link">&para;</a></h2> <ul> <li>Singular Value Decomposition (SVD) is a kind of generalized PCA (Principal Components Analysis).</li> </ul> <h3 id=review-materials>Review materials<a class=headerlink href=#review-materials title="Permanent link">&para;</a></h3> <ul> <li>Gradient Descent (SGD)</li> <li>Singular Value Decomposition (SVD)</li> <li>cross entropy loss</li> <li>max-margin loss</li> </ul> <h2 id=lecture-4-word-window-classification-and-neural-networks>Lecture 4 Word Window Classification and Neural Networks<a class=headerlink href=#lecture-4-word-window-classification-and-neural-networks title="Permanent link">&para;</a></h2> <ul> <li>Window classification: Train softmax classifier by assigning a label to a center word and concatenating all word vectors surrounding it.</li> <li>max-margin loss; <span><span class=MathJax_Preview>J(\theta) = \max(0, 1 - s + s_{corrupted})</span><script type=math/tex>J(\theta) = \max(0, 1 - s + s_{corrupted})</script></span>. <span><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span> is the good part, <span><span class=MathJax_Preview>s_{corrupted}</span><script type=math/tex>s_{corrupted}</script></span> is the bad part, we would like the bad part is smaller than <span><span class=MathJax_Preview>s - 1</span><script type=math/tex>s - 1</script></span>.</li> <li>backpropagation:<ul> <li>insight: reuse the derivative computed previously</li> <li>Hadamard product (<span><span class=MathJax_Preview>\circ, \odot, \otimes</span><script type=math/tex>\circ, \odot, \otimes</script></span>)</li> </ul> </li> </ul> <h2 id=lecture-5-backpropagation-feb-24-2019>Lecture 5 Backpropagation (Feb 24, 2019)<a class=headerlink href=#lecture-5-backpropagation-feb-24-2019 title="Permanent link">&para;</a></h2> <h3 id=details-of-backpropagation>Details of backpropagation<a class=headerlink href=#details-of-backpropagation title="Permanent link">&para;</a></h3> <p>The backprop algorithm is essentially compute the gradient (partial derivative) of the cost function with respect all the parameters, <span><span class=MathJax_Preview>U, W, b, x</span><script type=math/tex>U, W, b, x</script></span></p> <p>With the following setup:</p> <ul> <li>max-margin cost function: <span><span class=MathJax_Preview>J = \max(0, 1 - s + s_c)</span><script type=math/tex>J = \max(0, 1 - s + s_c)</script></span></li> <li>Scores: <span><span class=MathJax_Preview>s = U^T f(Wx + b), s_c = U^T f(Wx_c + b)</span><script type=math/tex>s = U^T f(Wx + b), s_c = U^T f(Wx_c + b)</script></span></li> <li>input: <span><span class=MathJax_Preview>z = Wx + b</span><script type=math/tex>z = Wx + b</script></span>, hidden: <span><span class=MathJax_Preview>a = f(z)</span><script type=math/tex>a = f(z)</script></span>, output: <span><span class=MathJax_Preview>s = U^T a</span><script type=math/tex>s = U^T a</script></span></li> <li>Derivatives:<ul> <li><span><span class=MathJax_Preview>\frac{\partial s}{\partial U} = \frac{\partial}{\partial U} U^T a = a</span><script type=math/tex>\frac{\partial s}{\partial U} = \frac{\partial}{\partial U} U^T a = a</script></span></li> <li>wrt one weight <span><span class=MathJax_Preview>W_{ij}</span><script type=math/tex>W_{ij}</script></span>: <span><span class=MathJax_Preview>\frac{\partial s}{\partial W_{ij}} = \delta_i x_j</span><script type=math/tex>\frac{\partial s}{\partial W_{ij}} = \delta_i x_j</script></span>, <span><span class=MathJax_Preview>\delta_i = U_i f'(z_i) x_j</span><script type=math/tex>\delta_i = U_i f'(z_i) x_j</script></span>, where <span><span class=MathJax_Preview>f'(z) = f(z)(1 - f(z))</span><script type=math/tex>f'(z) = f(z)(1 - f(z))</script></span>, <span><span class=MathJax_Preview>f(x)</span><script type=math/tex>f(x)</script></span> is logistic function or sigmoid function.</li> <li>wrt all weights <span><span class=MathJax_Preview>W</span><script type=math/tex>W</script></span>: <span><span class=MathJax_Preview>\frac{\partial s}{\partial W} = \delta x^T</span><script type=math/tex>\frac{\partial s}{\partial W} = \delta x^T</script></span></li> <li>wrt word vectors <span><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span>: <span><span class=MathJax_Preview>\frac{\partial s}{\partial x} = W^T\delta</span><script type=math/tex>\frac{\partial s}{\partial x} = W^T\delta</script></span></li> </ul> </li> </ul> <h3 id=iterpretations-of-backpropagation-using-simple-function>Iterpretations of backpropagation using simple function.<a class=headerlink href=#iterpretations-of-backpropagation-using-simple-function title="Permanent link">&para;</a></h3> <h2 id=lecture-6-dependency-parsing-feb-27-2019>Lecture 6 Dependency Parsing (Feb 27, 2019)<a class=headerlink href=#lecture-6-dependency-parsing-feb-27-2019 title="Permanent link">&para;</a></h2> <h2 id=lecture-8>Lecture 8<a class=headerlink href=#lecture-8 title="Permanent link">&para;</a></h2> <h2 id=lecture-9-machine-translation-and-advanced-recurrent-lstms-and-grus>Lecture 9 Machine Translation and Advanced Recurrent LSTMs and GRUs<a class=headerlink href=#lecture-9-machine-translation-and-advanced-recurrent-lstms-and-grus title="Permanent link">&para;</a></h2> <h2 id=reference>Reference<a class=headerlink href=#reference title="Permanent link">&para;</a></h2> <ul> <li><a href=http://www.nltk.org/book/ >Natural Language Processing with Python</a></li> </ul> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid"> <a href=../../../books/accelerated-cpp/notes/ title="Accelerated C++" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i> </div> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class=md-flex__ellipsis> <span class=md-footer-nav__direction> Previous </span> Accelerated C++ </span> </div> </a> <a href=../write-up/ title="CS224N Write-up" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel=next> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class=md-flex__ellipsis> <span class=md-footer-nav__direction> Next </span> CS224N Write-up </span> </div> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 Rui Han </div> powered by <a href=https://www.mkdocs.org target=_blank rel=noopener>MkDocs</a> and <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs</a> </div> </div> </div> </footer> </div> <script src=../../../assets/javascripts/application.c33a9706.js></script> <script>app.initialize({version:"1.1",url:{base:"../../.."}})</script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script> </body> </html>